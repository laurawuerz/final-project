{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# UCI Machine Learning - Drug Review Dataset\n\n**Content:**\n1. [Introduction](#introduction)\n2. [Data Preparation](#paragraph1)\n3. [Exploratory Data Analysis](#paragraph2)\n4. [ANOVA Test](#paragraph3)\n5. [Sentiment Analysis](#paragraph4)\n\n## Introduction <a name=\"introduction\"></a>\n\n**Attribute Information:**\n\n* drugName (categorical): name of drug\n* condition (categorical): name of condition\n* review (text): patient review\n* rating (numerical): 10 star patient rating\n* date (date): date of review entry\n* usefulCount (numerical): number of users who found review useful\n\nThe structure of the data is that a patient with a unique ID purchases a drug that meets his condition and writes a review and rating for the drug he/she purchased on the date. Afterwards, if the others read that review and find it helpful, they will click usefulCount, which will add 1 for the variable.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing libraries & magic functions\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n%config InlineBackend.figure_format ='retina'\n%matplotlib inline\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', -1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Putting Test and Train Set back together\n\ndstest = pd.read_csv('/kaggle/input/kuc-hackathon-winter-2018/drugsComTest_raw.csv')\ndstrain = pd.read_csv('/kaggle/input/kuc-hackathon-winter-2018/drugsComTrain_raw.csv')\n\ndstest.shape\ndstrain.shape\n\nds = pd.concat([dstest, dstrain],ignore_index=True)\nds.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation<a name=\"paragraph1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First glimpse at data\nds.head()\n\n# Statistics Summary - Numerical variables\nds.describe()\n\n# check types\nds.dtypes\n\n# check for missing data\nds.isna().sum()\n\n# check for duplicates\nduplicate_ds = ds[ds.duplicated()]\nduplicate_ds\nduplicate_ds.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop rows with missing values\nds = ds.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.isna().sum()\nds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change date to datetime format\n\nds.date = pd.to_datetime(ds.date)\nds.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set date as index\n\nds.set_index('date', inplace=True)\nds.info()\nds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.condition.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicate_review = ds[ds.duplicated(['review'])]\nduplicate_review","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.review.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regex_pattern = r'I wrote my first report in Mid-October(?!$)'\nds[ds['review'].str.contains(regex_pattern)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Many reviews are duplicated and have been assigned to 2 drugNames where 1 is usually a broader term for the drug and the second one the brand name. \n# We will therefore remove the duplicates and always keep the first value.\n\nds = ds.drop_duplicates(subset='review', keep=\"first\")\nds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for outliers\n\n#sns.boxplot(ds.usefulCount)\nsns.boxplot(ds.rating)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check distribution/correlation/outliers\nsns.pairplot(ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.groupby('condition').agg('sum')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.condition.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_comment = ds[ds['condition'].str.contains('comment')]\nds_comment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping rows that contain incorrect information \n\nds = ds[~ds['condition'].str.contains('comment')]\nds.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis <a name=\"paragraph2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_clean = ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_clean.condition.nunique()\nds_clean.drugName.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of drugs within conditions\n\nds_drugs_per_cond = ds_clean.groupby('condition').drugName.nunique().sort_values(ascending=False)\npd.DataFrame (data=ds_drugs_per_cond)\nds_drugs_per_cond = ds_drugs_per_cond.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Distribution of drugs within conditions\nplt.figure(figsize=(10,8))\nsns.barplot(x='drugName', y='condition', data=ds_drugs_per_cond[0:10], color='lightblue')\nplt.box(False)\nplt.xlabel(\"\", fontsize = 12)\nplt.ylabel(\"\", fontsize = 14)\nplt.title(\"Top 10 Number of Drugs by Condition\", fontsize = 18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_drugs_per_cond.head()\nds_drugs_per_cond['drugName'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Distribution Drugs Numbers per Condition\nmean=ds_drugs_per_cond['drugName'].mean()\nplt.figure(figsize=(11,5))\n#sns.set_style(\"white\")\nax = sns.distplot(ds_drugs_per_cond['drugName'],color='lightblue')\nax.axvline(mean, color='r', linestyle='--')\nplt.box(False)\nplt.legend({'Mean= 8.65':mean})\nplt.xlabel(\"\\n Number of different drugs\", fontsize = 12)\nplt.ylabel(\"\", fontsize = 12)\nplt.title(\"Distribution Drugs per Condition\", fontsize = 16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spread? Standard Deviation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying number of reviewed drugs by condition\n\nds_reviews_per_condition = ds_clean.groupby('condition').agg({'review':'count'})\nds_reviews_per_condition = ds_reviews_per_condition.sort_values(by='review', ascending=False)#[0:20]\nds_reviews_per_condition = ds_reviews_per_condition.reset_index()\nds_reviews_per_condition.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting reviews per conditions \nplt.figure(figsize=(12,6))\nsns.barplot(x='review', y='condition', data=ds_reviews_per_condition[0:10], color='lightblue')\nplt.box(False)\nplt.xlabel(\"\", fontsize = 12)\nplt.ylabel(\"\", fontsize = 14)\nplt.title(\"Top 10 Number of Reviews by Condition\\n\", fontsize = 18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group Rating and Condition\nds_rating = ds.groupby('condition').agg({'rating':'mean', 'review':'count'}).sort_values(by='rating',ascending=False)\nds_rating_150 = ds_rating[ds_rating.review>150] # we want to exclude those ratings that only received 1 review so we set the threshold approx. to the mean \nds_rating_150 = ds_rating_150.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_rating_150.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_rating_drug = pd.merge(left=ds_rating_150,right=ds_drugs_per_cond, how='left', left_on='condition', right_on='condition')\nds_rating_drug.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between rating scores and number of drug - grouped by condition\nnp.corrcoef(ds_rating_drug[\"rating\"], ds_rating_drug[\"drugName\"])\nsns.scatterplot(x='rating', y='drugName', data=ds_rating_drug, color='lightblue')\nplt.box(False)\nplt.xlabel(\"Rating\", fontsize = 10)\nplt.ylabel(\"Number of Drugs\\n\", fontsize = 12)\nplt.title(\"Rating and Number of Drugs\", fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_rating_150.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_rating_150['rating'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Rating for more than 150 reviews received\nmean=ds_rating_150['rating'].mean()\n\nax=sns.distplot(ds_rating_150['rating'], color='lightblue')\nax.axvline(mean, color='r', linestyle='--')\n\nplt.legend({'Mean= 7.152':mean})\n\nplt.box(False)\nplt.xlabel(\"Rating\", fontsize = 10)\nplt.ylabel(\"\", fontsize = 12)\nplt.title(\"Rating Distribution\", fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_outlier = ds_rating_150[ds_rating_150[\"review\"]>15000]\n# Remove outlier\n\nds_rating_150 = ds_rating_150.drop([ds_rating_150.index[91]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between rating scores and numbe rof reviews received - grouped by condition\nnp.corrcoef(ds_rating_150[\"rating\"], ds_rating_150[\"review\"])\nsns.scatterplot(x='rating', y='review', data=ds_rating_150, color='lightblue')\nplt.box(False)\nplt.xlabel(\"Rating\", fontsize = 10)\nplt.ylabel(\"Number of Reviews\\n\", fontsize = 12)\nplt.title(\"Rating and Number of Reviews\", fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_rating_150.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ds_clean['reviews_per_cond'] = ds_rating[\"review\"]\nds_merged_left = pd.merge(left=ds_clean,right=ds_rating, how='left', left_on='condition', right_on='condition')\n\nds_merged_left.head()\nds_merged_left.shape\nds_merged_left.isna().sum()\nds_merged_left_150 = ds_merged_left[ds_merged_left['review_y'] > 150]\nds_merged_left_150.head()\nds_merged_left_150.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming columns\nds_merged_left_150.columns\n\nds_merged_left_150 = ds_merged_left_150.rename(columns={'rating_y':'Mean Rating',\n                        'review_y':'Number of Reviews per condition'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_merged_left_150.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Development over Time"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_time['Year'] = ds_time.index.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Time Series\nds_time= ds_clean.sort_index()\nds_time.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ANOVA TEST <a name=\"paragraph3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\nmod=ols('rating_x  ~ condition',data=ds_merged_left_150).fit()\n\naov_table = sm.stats.anova_lm(mod, typ=2)\nprint(aov_table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"esq_sm = aov_table['sum_sq'][0]/(aov_table['sum_sq'][0]+aov_table['sum_sq'][1])\naov_table['EtaSq'] = [esq_sm, 'NaN']\nprint(aov_table)\naov_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.boxplot(scores~group,data=data)\nmod.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nds_rating_150.head()\nds_rating_150 = ds_rating_150.replace({'mance Anxiety': 'Anxiety'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Ratings per condition \nplt.figure(figsize=(10,5))\nsns.barplot(x='condition', y='rating', data=ds_rating_150[0:5].sort_values(by='rating', ascending=False), color='lightgreen')\nplt.box(False)\nplt.xlabel(\"\\nCondition\", fontsize = 14)\nplt.ylabel(\"Average Rating\", fontsize = 14)\nplt.title(\"5 best Ratings by Condition\", fontsize = 20)\n#plt.setp(ax.get_xticklabels(), fontsize=14)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Ratings per condition\nplt.figure(figsize=(12,5))\nsns.barplot(x='condition', y='rating', data=ds_rating_150[-6:-1].sort_values(by='rating', ascending= False), color=\"darkred\")\n#sns.set(rc={'figure.figsize':(22,10)})\nplt.box(False)\nplt.xlabel(\"\\nCondition\", fontsize = 14)\nplt.ylabel(\"Average Rating\", fontsize = 14)\nplt.title(\"5 worst Ratings by Condition\", fontsize = 20)\n#plt.setp(ax.get_xticklabels(), fontsize=14)\naxes = plt.gca()\n#axes.set_xlim([xmin,xmax])\naxes.set_ylim([0,10])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_rating.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_time_drug = ds_time.groupby('Year')['drugName'].nunique()\nds_time_drug\nds_time_drug.plot(kind='line')\nplt.title('Number of Drugs by Year')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_time_review = ds_time.groupby('Year')['review'].agg(['count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_time_review.plot(kind='line')\nplt.title('Number of Reviews collected per Year')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_time_rating = ds_time.groupby('Year')['rating'].agg(['mean'])\nds_time_rating","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_time_rating.plot(kind='line')\nplt.title('Average Rating Score by Year')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Wordcloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_merged_left_150.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_wordcloud(ds_merged_left_150):\n    \n    stopwords_list = stopwords.words('english') + list(STOPWORDS) \n    \n    raw_text = \" \".join(ds_merged_left_150['review_x'].values)\n    \n    #mask = np.array(Image.open(\"/kaggle/input/lalalaa/pill.png\"))\n    \n    wc = WordCloud(stopwords=stopwords_list, background_color=\"white\",width= 1600, height=800, max_words=150).generate(raw_text)\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis(\"off\")\n    fig = plt.gcf()\n    fig.set_size_inches(16, 8)\n    plt.show()\n\nreviews_by_comments = ds_merged_left_150.sort_values(by=\"usefulCount\", ascending=False)\n\ntop_100_useful_comments = reviews_by_comments.head(100)\n\ngenerate_wordcloud(ds_merged_left_150)\n\ngenerate_wordcloud(top_100_useful_comments)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment Analysis<a name=\"paragraph4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nimport spacy\nfrom spacy.lang.en.examples import sentences \nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.tokenize.toktok import ToktokTokenizer\nimport re\nfrom bs4 import BeautifulSoup\nimport unicodedata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm', parse = True, tag=True, entity=True)\n#nlp = spacy.load()\n#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, entity=True)\ntokenizer = ToktokTokenizer()\nstopword_list = nltk.corpus.stopwords.words('english')\nstopword_list.remove('no')\nstopword_list.remove('not')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove HTML\n\ndef strip_html_tags(text):\n    soup = BeautifulSoup(text, \"html.parser\")\n    stripped_text = soup.get_text()\n    return stripped_text\n\nstrip_html_tags('<html><h2>Some important text</h2></html>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove accented characters\n\ndef remove_accented_chars(text):\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    return text\n\nremove_accented_chars('Sómě Áccěntěd těxt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove special characters\n\ndef remove_special_characters(text, remove_digits=False):\n    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n    text = re.sub(pattern, '', text)\n    return text\n\nremove_special_characters(\"Well this was fun! What do you think? 123#@!\", \n                          remove_digits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Text lemmatization\n\ndef lemmatize_text(text):\n    text = nlp(text)\n    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n    return text\n\nlemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Text stemming\n\ndef simple_stemmer(text):\n    ps = nltk.porter.PorterStemmer()\n    text = ' '.join([ps.stem(word) for word in text.split()])\n    return text\n\nsimple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove stopwords\n\ndef remove_stopwords(text, is_lower_case=False):\n    tokens = tokenizer.tokenize(text)\n    tokens = [token.strip() for token in tokens]\n    if is_lower_case:\n        filtered_tokens = [token for token in tokens if token not in stopword_list]\n    else:\n        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n    filtered_text = ' '.join(filtered_tokens)    \n    return filtered_text\n\nremove_stopwords(\"The, and, if are stopwords, computer is not\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Text normalizer\n\ndef normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n                     accented_char_removal=True, text_lower_case=True, \n                     text_lemmatization=True, special_char_removal=True, \n                     stopword_removal=True, remove_digits=True):\n    \n    normalized_corpus = []\n    # normalize each document in the corpus\n    for doc in corpus:\n        # strip HTML\n        if html_stripping:\n            doc = strip_html_tags(doc)\n        # remove accented characters\n        if accented_char_removal:\n            doc = remove_accented_chars(doc)\n        # lowercase the text    \n        if text_lower_case:\n            doc = doc.lower()\n        # remove extra newlines\n        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n        # lemmatize text\n        if text_lemmatization:\n            doc = lemmatize_text(doc)\n        # remove special characters and\\or digits    \n        if special_char_removal:\n            # insert spaces between special characters to isolate them    \n            special_char_pattern = re.compile(r'([{.(-)!}])')\n            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n        # remove extra whitespace\n        doc = re.sub(' +', ' ', doc)\n        # remove stopwords\n        if stopword_removal:\n            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n            \n        normalized_corpus.append(doc)\n        \n    return normalized_corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sampling (takes too long otherwise)\n\nds_merged_left_150.shape\nds_merged_left_150.head()\n\nds_merged_left_150_sample = ds_merged_left_150.sample(frac=0.02, replace=False, random_state=5)\nds_merged_left_150_sample = ds_merged_left_150_sample.reset_index()\nds_merged_left_150_sample.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add column with cleaned text to the dataframe\nds_merged_left_150_sample['clean_text'] = normalize_corpus(ds_merged_left_150_sample['review_x'])\nds_merged_left_150_sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\n    \ndef detect_polarity(text):\n    return TextBlob(text).sentiment.polarity\n\nds_merged_left_150_sample['polarity'] = ds_merged_left_150_sample['clean_text'].apply(detect_polarity)\nds_merged_left_150_sample.head()\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding sentiment scores for raw review text\n\nds_merged_left_150_sample['polarity_raw'] = ds_merged_left_150_sample['review_x'].apply(detect_polarity)\nds_merged_left_150_sample.head()\n     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping polsub columns (not necessary anymore since we split Polarity and Subjectivity)\n\n#ds_merged_left_150_sample = ds_merged_left_150_sample.drop(['pol_sub','pol_sub2'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation btw polarity scores and rating scores\n# Spearman correlation between computed polarity and given rating\n\nfrom scipy.stats import spearmanr\nspearmanr(ds_merged_left_150_sample['polarity'], ds_merged_left_150_sample['rating_x'])\n\n# Testing with raw data\nspearmanr(ds_merged_left_150_sample['polarity_raw'], ds_merged_left_150_sample['rating_x'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.corrcoef(ds_merged_left_150_sample[\"rating_x\"], ds_merged_left_150_sample[\"polarity\"])\n\n# Testing with raw data\nnp.corrcoef(ds_merged_left_150_sample[\"rating_x\"], ds_merged_left_150_sample[\"polarity_raw\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6,6))\nsns.scatterplot(x='rating_x', y='polarity', data=ds_merged_left_150_sample)\nplt.box(False)\nplt.xlabel(\"Rating\", fontsize = 12)\nplt.ylabel(\"Polarity\", fontsize = 12)\nplt.title(\"Correlation Rating and Polarity\", fontsize = 18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.boxplot(x=ds_merged_left_150_sample[\"rating_x\"],y=ds_merged_left_150_sample[\"polarity\"])\nplt.xlabel(\"Rating\")\nplt.ylabel(\"Polarity\")\nplt.title(\"Polarity vs Ratings\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of Polarity scores across sample\n\nplt.figure(figsize=(6,6))\nsns.set_style('white')\nsns.distplot(ds_merged_left_150_sample['polarity'])\nplt.box(False)\nplt.title(\"Polarity Distribution\", fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of Rating scores across sample\nplt.figure(figsize=(6,6))\nsns.distplot(ds_merged_left_150_sample['rating_x'])\nplt.box(False)\nplt.xlabel('Rating')\nplt.title(\"Rating Distribution\", fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding pos/neg/neutral labels\n\ndef f(row):\n    if row['polarity'] >= 0.3:\n        val = 'positive'\n    elif row['polarity'] <=-0.3:\n        val = 'negative'\n    else:\n        val = 'neutral'\n    return val\n\nds_merged_left_150_sample['Sentiment'] = ds_merged_left_150_sample.apply(f, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_merged_left_150_sample[ds_merged_left_150_sample.polarity == -1].head()\nds_merged_left_150_sample[ds_merged_left_150_sample.polarity == 1].head()\n#ds_merged_left_150_sample.tail(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(ds_merged_left_150_sample['Sentiment'])#.sort_values(by)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_merged_left_150_sample = ds_merged_left_150_sample.drop(['index'], axis=1)\n#ds_merged_left_150_sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_merged_left_150_sample_displ = ds_merged_left_150_sample.drop(['usefulCount','Mean Rating','Number of Reviews per condition','polarity_raw'], axis=1) \ntype(ds_merged_left_150_sample_displ)\nds_merged_left_150_sample_displ.loc[[336]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_merged_left_150_sample_displ[ds_merged_left_150_sample_displ.polarity == -1].head()\nds_merged_left_150_sample_displ[ds_merged_left_150_sample_displ.polarity == 1].head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}